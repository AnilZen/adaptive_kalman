[{"id":0,"href":"/adaptive_regression/code/lorenz-96/","title":"Lorenz-96 Model","parent":"Code","content":"The Lorenz-96 model is a chaotic, continuous-in-time, discrete-in-space, dynamical system that was proposed by Lorenz in 1996 as a toy model for weather dynamics1.\n$$ \\frac{dx_j}{dt} = ( x_{j+1} - x_{j-2} ) x_{j-1} - x_j + F(t). $$ Even though the equations have been used and studied for a long time, their chaotic behavior has been mathematically proven only recently2.\nThe system is implemented in helpers.py in class Lorenz.\nParameters     N: Number of grid points, defaults to 40. dt: Time step, defaults to 0.05. This is hard-coded for forecasts, so be careful when you change it. The error growth time scale is assumed to be such that 0.05 corresponds to 6 hours in an operational weather forecast system. forcing: External forcing function, defaults to the traditional choice of 8, where the system behaves chaotically.  Methods     rk4 is a 4th order Runge-Kutta integrator for solving the Lorenz system of ODEs. rhs implements the right hand side using vectorized numpy expressions.  dotx[2:-1] = (x[3:]-x[0:-3])*x[1:-2] - x[2:-1] + forcing[2:-1] Periodic boundary conditions are imposed on the outer grid points.\n solve solves the system of ODEs for a number of days with given initial data. The method populates the sol attribute by integrating the system using a 4th order Runge-Kutta method. The core portion of the method is  self.sol[0] = init_data for i in range(1, self.nt+1): self.sol[i] = self.rk4(self.sol[i-1]) self.t += self.dt The total number of time steps nt is determined from the days and the time step via self.nt = int(4*0.05/self.dt*days) as dt=0.05 corresponds to 6 hours.\n animate is provided to view the dynamic solution in time.  Usage    The default system can be initiated with random data, solved for 90 days, and visualized by\nN=40; F=8; initial_data=np.random.normal(0.25*F,0.5*F,N) Default=Lorenz() Default.solve(days=90,init_data=initial_data) anim=Default.animate()   Lorenz, E.N., 1996. Predictability: A problem partly solved. ECMWF Proc. Seminar on predictability (Vol. 1, No. 1). \u0026#x21a9;\u0026#xfe0e;\n Bedrossian, J., Blumenthal, A. and Punshon-Smith, S., 2020. A regularity method for lower bounds on the Lyapunov exponent for stochastic differential equations. arXiv preprint arXiv:2007.15827. \u0026#x21a9;\u0026#xfe0e;\n   "},{"id":1,"href":"/adaptive_regression/code/forecast/","title":"Biased Forecast","parent":"Code","content":"Forecasts are made using the Forecast class, which inherits from Lorenz. The time step and the number of grid points in the related Lorenz system are hard-coded to 40 and 0.05 respectively.\nParameters    Forecasts are made from initial data provided by Nature at certain stations for a certain number of forecast days using a biased model. Therefore, the parameters are\n Nature: Nature reference array (Lorenz.sol). Forecast quality is compared to Nature. Nature also provides initial data for the forecasts. stations: Stations are represented as grid points of the model. Forecasts are made at those grid points. Since the model is periodic, the specific distribution of stations is not important. forecast_days: The range of each forecast. forcing: The forcing for the forecast model should be different from the Nature forcing to introduce deliberate bias into the forecasts.  Making a deliberately biased forecast    The method make_forecast solves the biased Lorenz model up to the forecast day for each day in the Nature run. It populates the attributes forecast and station_forecast. For each day within the Nature run, the biased model is solved for the number of forecast days and the full solution is stored in forecast. So Forecast.forecast is an array shaped like (total_days+1, 4*forecast_days+1, N). A subset of this array is stored under station_forecast corresponding to the location of the stations.\nA forcing with constant and stochastics perturbations to Nature can be defined as\nf_const=lambda t: (F+0.1)*np.ones(N) f_random=lambda t: F+np.random.normal(0,0.6,N) These forcings lead to the errors plotted below for the first station.\nThe plot takes the Nature solution and subtracts from it the biased forecast for each day of the Nature run. For example, for the constant forcing perturbation we plot\nfor k in range(constant.nature_days-forecast_days): plt.plot(constant.hours, Nature.sol[4*k:4*k+4*forecast_days+1,stations[0]]-\\ constant.station_forecast[k,:,0],\u0026#39;k--\u0026#39;,lw=0.4) "},{"id":2,"href":"/adaptive_regression/code/adaptive-regression/","title":"Adaptive Regression","parent":"Code","content":"The adaptive regression (AR) method uses Kalman Filters.\n"},{"id":3,"href":"/adaptive_regression/experiment/forecasting/","title":"Forecasting","parent":"Experiment","content":"Nature    "},{"id":4,"href":"/adaptive_regression/blog/","title":"Blog","parent":"","content":"List\n"},{"id":5,"href":"/adaptive_regression/","title":"","parent":"","content":"Adaptive Regression with Kalman Filters    This documentation describes an adaptive regression code that postprocesses numerical model output to correct systematic biases. The method is demonstrated on the Lorenz-96 model. Forecasts based on Model Output Statistics and Adaptive Regression are compared in a 5-year run.\nThe idea goes back to Eugenia Kalnay who first described it in her lecture notes on statistical forecasting. Experiments with the Lorenz model support her conclusions at the end of her lecture notes:\n Kalman Filtering provides a simple algorithm for adaptive regression. It requires little training so that it is able to adapt rather quickly to changes in the model, and to long-lasting weather regimes. It is particularly good in correcting model biases. However, in general it is not as good as regression based on long dependent samples.\n Model Output Statistics performs better under ideal conditions with long dependent samples. However, there are a few reasons to prefer adaptive regression in an operational setting:\n Climate change is causing long-lasting weather regimes that are different from the usual weather patterns of the past. Numerical weather forecasting is in rapid development. Models are upgraded frequently to incorporate more detailed physics. Long-term training data for a given model may not be available and/or may be costly to obtain. Adaptive regression incorporates \u0026ldquo;errors of the day\u0026rdquo;.  We explore these conclusions quantitatively using a simple Python implementation of adaptive regression. The documentation describes the parameters and methods implemented in the code. For usage, please refer to the Jupyter notebook Lorenz.ipynb.\n"},{"id":6,"href":"/adaptive_regression/blog/noaa-request/","title":"NOAA Request","parent":"Blog","content":"We asked for data to test the method, but our request was declined.\n"},{"id":7,"href":"/adaptive_regression/blog/starting-point/","title":"Starting Point","parent":"Blog","content":"I took a class by Eugenia on data assimilation, and this topic was discussed.\n"},{"id":8,"href":"/adaptive_regression/categories/","title":"Categories","parent":"","content":""},{"id":9,"href":"/adaptive_regression/code/","title":"Code","parent":"","content":""},{"id":10,"href":"/adaptive_regression/experiment/","title":"Experiment","parent":"","content":""},{"id":11,"href":"/adaptive_regression/code/mos/","title":"MOS Forecast","parent":"Code","content":"A MOS forecast starts with the computation of the regression parameters using the method regression_pars, which performs a linear, two-parameter regression. The predictor is the station forecast and the predictand is the Nature solution evaluated at these stations. The comparison between the Nature solution and the forecast provides the regression parameters.\nWriting $x$ as the biased forecasts for each forecast hour (one predictor), $\\hat{y}$ as the corrected forecast (predictand), and $y$ as the Nature solution, we have $$ \\hat{y} = \\sum_k b_k x_k, \\qquad y = \\hat{y} + \\epsilon, $$\nwhere $\\epsilon$ is the forecast error and $k$ runs through 0,1 with $x_0=1$ and $x_1=x$. The forecast parameters $b_k$ are computed by requiring that the least-square error is minimized. Doing this for each forecast hour and representing the variables through matrices, we obtain for the matrix of regression parameters $$ B = (X^T X)^{-1} X^T Y,$$ where $Y$ is the vector of Nature solutions for each forecast hour, and $X$ is the matrix of biased forecasts (predictor) with 1\u0026rsquo;s at the first row. This is roughly implemented as follows.\nnt = 4*forecast_days+1 predictor = station_forecast for k in range(len(predictor)): predictand[k] = Nature[4*k:4*k+nt, station] for i in range(nt): X = vstack((ones(len(predictor)), predictor[:, i])).T b[i] = dot(dot(linalg.inv(dot(X.T, X)), X.T), predictand[:, i]) The main difficulty in the code is just accounting the rows and columns of the matrices.\nThe method make_mos_forecast uses the regression parameters to compute the forecast vector $\\hat{Y}$ for each station via $\\hat{Y}=X B$ which corresponds to the code\nmos_forecast = b[:, :, 0].T[np.newaxis, :]+b[:, :, 1].T*forecast[:, :, stations] "},{"id":12,"href":"/adaptive_regression/tags/","title":"Tags","parent":"","content":""}]