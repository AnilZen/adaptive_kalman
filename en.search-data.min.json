[{"id":0,"href":"/adaptive_regression/code/lorenz-96/","title":"Lorenz-96 Model","parent":"Code","content":"The Lorenz-96 model is a chaotic, continuous-in-time, discrete-in-space, dynamical system that was proposed by Lorenz in 1996 as a toy model for weather dynamics1.\n$$ \\frac{dx_j}{dt} = ( x_{j+1} - x_{j-2} ) x_{j-1} - x_j + F(t). $$ Even though the equations have been used and studied for a long time, their chaotic behavior has been mathematically proven only recently2.\nThe system is implemented in helpers.py in class Lorenz.\nParameters     N: Number of grid points, defaults to 40. dt: Time step, defaults to 0.05. This is hard-coded for forecasts, so be careful when you change it. The error growth time scale is assumed to be such that 0.05 corresponds to 6 hours in an operational weather forecast system. forcing: External forcing function, defaults to the traditional choice of 8, where the system behaves chaotically.  Methods     rk4 is a 4th order Runge-Kutta integrator for solving the Lorenz system of ODEs. rhs implements the right hand side using vectorized numpy expressions.  dotx[2:-1] = (x[3:]-x[0:-3])*x[1:-2] - x[2:-1] + forcing[2:-1] Periodic boundary conditions are imposed on the outer grid points.\n solve solves the system of ODEs for a number of days with given initial data. The method populates the sol attribute by integrating the system using a 4th order Runge-Kutta method. The core portion of the method is  self.sol[0] = init_data for i in range(1, self.nt+1): self.sol[i] = self.rk4(self.sol[i-1]) self.t += self.dt The total number of time steps nt is determined from the days and the time step via self.nt = int(4*0.05/self.dt*days) as dt=0.05 corresponds to 6 hours.\n animate is provided to view the dynamic solution in time.  Usage    The default system can be initiated with random data, solved for 90 days, and visualized by\nN=40; F=8; initial_data=np.random.normal(0.25*F,0.5*F,N) Default=Lorenz() Default.solve(days=90,init_data=initial_data) anim=Default.animate()   Lorenz, E.N., 1996. Predictability: A problem partly solved. ECMWF Proc. Seminar on predictability (Vol. 1, No. 1). \u0026#x21a9;\u0026#xfe0e;\n Bedrossian, J., Blumenthal, A. and Punshon-Smith, S., 2020. A regularity method for lower bounds on the Lyapunov exponent for stochastic differential equations. arXiv preprint arXiv:2007.15827. \u0026#x21a9;\u0026#xfe0e;\n   "},{"id":1,"href":"/adaptive_regression/code/forecast/","title":"Forecast","parent":"Code","content":"Forecasts are made using the Forecast class, which inherits from Lorenz. The time step and the number of grid points in the related Lorenz system are hard-coded to 40 and 0.05 respectively.\nParameters    Forecasts are made from initial data provided by Nature at certain stations for a certain number of forecast days using a biased model. Therefore, the parameters are\n Nature: Nature reference array (Lorenz.sol). Forecast quality is compared to Nature. Nature also provides initial data for the forecasts. stations: Stations are represented as grid points of the model. Forecasts are made at those grid points. Since the model is periodic, the specific distribution of stations turns out to be not so important. forecast_days: The range of each forecast. forcing: The forcing for the forecast model should be different from the Nature forcing to introduce deliberate bias into the forecasts.  Making a deliberately biased forecast    The method make_forecast solves the biased Lorenz model up to the forecast day for each day in the Nature run. It populates the attributes forecast and station_forecast. For each day within the Nature run, the biased model is solved for the number of forecast days and the full solution is stored in forecast. So Forecast.forecast is an array shaped like (total_days+1, 4*forecast_days+1, N). A subset of this array is stored under station_forecast corresponding to the location of the stations.\nMaking corrected forecasts using MOS    The method regression_pars performs a linear, two-parameter regression. The predictor is the station forecast and the predictand is the Nature solution evaluated at these stations. The comparison between the Nature solution and the forecast provides the regression parameters.\n make_mos_forecast  Making corrected forecasts using AR    Computing the quality of a forecast     error_norms process is a shorthand method to trigger each method of the forecast so all forecast attributes are populated.  Usage    "},{"id":2,"href":"/adaptive_regression/code/adaptive-regression/","title":"Adaptive Regression","parent":"Code","content":"Adaptive Regression (AR) is based on Kalman Filters.\n"},{"id":3,"href":"/adaptive_regression/experiment/forecasting/","title":"Forecasting","parent":"Experiment","content":"Nature    "},{"id":4,"href":"/adaptive_regression/blog/","title":"Blog","parent":"","content":"List\n"},{"id":5,"href":"/adaptive_regression/","title":"","parent":"","content":"Adaptive Regression with Kalman Filters    This documentation describes an adaptive regression code that postprocesses numerical model output to correct systematic biases. The method is demonstrated on the Lorenz-96 model. Forecasts based on Model Output Statistics and Adaptive Regression are compared in a 5-year run.\nThe idea goes back to Eugenia Kalnay who first described it in her lecture notes on statistical forecasting. Experiments with the Lorenz model support her conclusions at the end of her lecture notes:\n Kalman Filtering provides a simple algorithm for adaptive regression. It requires little training so that it is able to adapt rather quickly to changes in the model, and to long-lasting weather regimes. It is particularly good in correcting model biases. However, in general it is not as good as regression based on long dependent samples.\n Model Output Statistics performs better under ideal conditions with long dependent samples. However, there are a few reasons to prefer adaptive regression in an operational setting:\n Climate change is causing long-lasting weather regimes that are different from the usual weather patterns of the past. Numerical weather forecasting is in rapid development. Models are upgraded frequently to incorporate more detailed physics. Long-term training data for a given model may not be available and/or may be costly to obtain. Adaptive regression incorporates \u0026ldquo;errors of the day\u0026rdquo;.  We explore these conclusions quantitatively using a simple Python implementation of adaptive regression. The documentation describes the parameters and methods implemented in the code. For usage, please refer to the Jupyter notebook Lorenz.ipynb.\n"},{"id":6,"href":"/adaptive_regression/blog/noaa-request/","title":"NOAA Request","parent":"Blog","content":"We asked for data to test the method, but our request was declined.\n"},{"id":7,"href":"/adaptive_regression/blog/starting-point/","title":"Starting Point","parent":"Blog","content":"I took a class by Eugenia on data assimilation, and this topic was discussed.\n"},{"id":8,"href":"/adaptive_regression/categories/","title":"Categories","parent":"","content":""},{"id":9,"href":"/adaptive_regression/code/","title":"Code","parent":"","content":""},{"id":10,"href":"/adaptive_regression/experiment/","title":"Experiment","parent":"","content":""},{"id":11,"href":"/adaptive_regression/code/mos/","title":"Model Output Statistics","parent":"Code","content":"Model Output Statistics (MOS) is sophisticated linear regression.\n"},{"id":12,"href":"/adaptive_regression/tags/","title":"Tags","parent":"","content":""}]